# initialize.py
import os
import streamlit as st
from dotenv import load_dotenv
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader, PyPDFLoader, CSVLoader

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# âœ… APIã‚­ãƒ¼ç¢ºèª
if not os.getenv("OPENAI_API_KEY"):
    st.warning("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

# å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µå¯èƒ½ï¼‰
SUPPORTED_FILES = [
    "data/æ³•äººé¡§å®¢ã¨ã®ä¼šè©±ã‚¹ã‚¯ãƒªãƒ—ãƒˆ.txt",
    "data/æ³•äººé¡§å®¢ã¨ã®ä¼šè©±ã‚¹ã‚¯ãƒªãƒ—ãƒˆ.pdf",
    "data/æ³•äººé¡§å®¢ã¨ã®ä¼šè©±ã‚¹ã‚¯ãƒªãƒ—ãƒˆ.csv"
]

# æ–‡æ›¸èª­ã¿è¾¼ã¿é–¢æ•°
def load_document(file_path: str):
    ext = os.path.splitext(file_path)[1].lower()
    try:
        if ext == ".txt":
            return TextLoader(file_path, encoding="utf-8").load()
        elif ext == ".pdf":
            return PyPDFLoader(file_path).load()
        elif ext == ".csv":
            return CSVLoader(file_path).load()
        else:
            raise ValueError(f"âŒ æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {ext}")
    except Exception as e:
        st.error(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        raise RuntimeError(e)

# ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼šãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ç”Ÿæˆ
def initialize_documents():
    for file_path in SUPPORTED_FILES:
        if os.path.exists(file_path):
            docs = load_document(file_path)
            if not docs:
                raise ValueError("ğŸ“‚ èª­ã¿è¾¼ã‚“ã æ–‡æ›¸ãŒç©ºã§ã™ã€‚")
            break
    else:
        st.error("âŒ å¯¾å¿œã™ã‚‹æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        raise FileNotFoundError("æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

    # åˆ†å‰²ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    splitted_docs = splitter.split_documents(docs)

    embeddings = OpenAIEmbeddings()
    vectorstore = Chroma.from_documents(
        splitted_docs,
        embedding=embeddings,
        persist_directory="./.db"
    )
    return vectorstore
